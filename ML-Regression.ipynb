{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ada122",
   "metadata": {},
   "source": [
    "## ML REGRESSION ALGORITHMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec1e4d",
   "metadata": {},
   "source": [
    "Loading the scikit-learn version of the diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b478c62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5ce38",
   "metadata": {},
   "source": [
    "Splitting the dataset into the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5effd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(diabetes['data'],diabetes['target'], random_state=2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb342359",
   "metadata": {},
   "source": [
    "Implementing Lasso model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbb2365",
   "metadata": {},
   "source": [
    "Calculating the training and test R2 for the Lasso model using the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "516a7828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 = 0.3604688303389487\n",
      "Test R2 = 0.3438980595081287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso1 = Lasso().fit(X1_train,y1_train)\n",
    "training_R2 = lasso1.score(X1_train,y1_train)\n",
    "test_R2 = lasso1.score(X1_test,y1_test)\n",
    "print('Training R2 =',training_R2)\n",
    "print('Test R2 =',test_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97bd8d1",
   "metadata": {},
   "source": [
    "Checking the features used by Lasso model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6267b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of features used by lasso model = 3\n",
      "Features used by Lasso model are: [['bmi' 'bp' 's5']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Finding how many features are used\n",
    "feature_count = np.sum(lasso1.coef_ != 0)\n",
    "print('Count of features used by lasso model =',feature_count)\n",
    "\n",
    "#Finding the names of used features\n",
    "feature_indices = np.argwhere(lasso1.coef_ != 0)\n",
    "features_used = np.array(diabetes['feature_names'])[feature_indices]\n",
    "print('Features used by Lasso model are:',(features_used.transpose()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f72c64",
   "metadata": {},
   "source": [
    "Loading the original version of the diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24114cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_org = np.genfromtxt(\"diabetes.data\", delimiter=\"\\t\",skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e5a874",
   "metadata": {},
   "source": [
    "Splitting the original dataset into the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d293da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data = np.genfromtxt(\"diabetes.data\", delimiter=\"\\t\",usecols=np.arange(diabetes_org.shape[1]-1),skip_header=1)\n",
    "diabetes_target = np.genfromtxt(\"diabetes.data\", delimiter=\"\\t\",usecols=diabetes_org.shape[1]-1, dtype='int',skip_header=1)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(diabetes_data,diabetes_target, random_state=2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f14cc",
   "metadata": {},
   "source": [
    "Implementing Lasso model on original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd02ce",
   "metadata": {},
   "source": [
    "Calculating the training and test R2 for the Lasso model using the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4be6206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 = 0.5081103067515702\n",
      "Test R2 = 0.49876675224257616\n"
     ]
    }
   ],
   "source": [
    "lasso2 = Lasso().fit(X2_train,y2_train)\n",
    "training_R2 = lasso2.score(X2_train,y2_train)\n",
    "test_R2 = lasso2.score(X2_test,y2_test)\n",
    "print('Training R2 =',training_R2)\n",
    "print('Test R2 =',test_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5c8c3",
   "metadata": {},
   "source": [
    "Checking the features used by Lasso model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "850b13ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of features used by lasso model = 10\n",
      "Features used by Lasso model are: [['age' 'sex' 'bmi' 'bp' 's1' 's2' 's3' 's4' 's5' 's6']]\n"
     ]
    }
   ],
   "source": [
    "#Finding how many features are used\n",
    "feature_count = np.sum(lasso2.coef_ != 0)\n",
    "print('Count of features used by lasso model =',feature_count)\n",
    "\n",
    "#Finding the names of used features\n",
    "feature_indices = np.argwhere(lasso2.coef_ != 0)\n",
    "features_used = np.array(diabetes['feature_names'])[feature_indices]\n",
    "print('Features used by Lasso model are:',(features_used.transpose()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22d0e63",
   "metadata": {},
   "source": [
    "Preprocessing the training and test sets and avoiding data snooping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b10c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "#Finding the transformation from the training set\n",
    "scaler.fit(X2_train)\n",
    "#To avoid data snooping, same transformation is applied to training and test sets\n",
    "X2_train_scaled = scaler.transform(X2_train)\n",
    "X2_test_scaled = scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c04127",
   "metadata": {},
   "source": [
    "We have now preprocessed the data. We can verify this by checking the standard deviations of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "627b9915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.std(X2_train_scaled,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60206d7f",
   "metadata": {},
   "source": [
    "Implementing the Lasso model on scaled dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80545ab",
   "metadata": {},
   "source": [
    "Calculating the training and test R2 for the Lasso model using the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c22f1ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R2 = 0.5103864679565968\n",
      "Test R2 = 0.5059896195946609\n"
     ]
    }
   ],
   "source": [
    "lasso3 = Lasso().fit(X2_train_scaled,y2_train)\n",
    "training_R2 = lasso3.score(X2_train_scaled,y2_train)\n",
    "test_R2 = lasso3.score(X2_test_scaled,y2_test)\n",
    "print('Training R2 =',training_R2)\n",
    "print('Test R2 =',test_R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda202c",
   "metadata": {},
   "source": [
    "Checking the features used by Lasso model above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02941593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of features used by lasso model = 9\n",
      "Features used by Lasso model are: [['age' 'sex' 'bmi' 'bp' 's1' 's3' 's4' 's5' 's6']]\n"
     ]
    }
   ],
   "source": [
    "#Finding how many features are used\n",
    "feature_count = np.sum(lasso3.coef_ != 0)\n",
    "print('Count of features used by lasso model =',feature_count)\n",
    "\n",
    "#Finding the names of used features\n",
    "feature_indices = np.argwhere(lasso3.coef_ != 0)\n",
    "features_used = np.array(diabetes['feature_names'])[feature_indices]\n",
    "print('Features used by Lasso model are:',(features_used.transpose()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6592f8",
   "metadata": {},
   "source": [
    "Varying the regularization parameter α in the Lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe90634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained values are as follows:\n",
      "alpha= 0.0001 : Test R2= 0.5055293533708054 \t Features Used= 10\n",
      "alpha= 0.001 : Test R2= 0.5055195334302462 \t Features Used= 10\n",
      "alpha= 0.01 : Test R2= 0.5054156114170519 \t Features Used= 10\n",
      "alpha= 0.1 : Test R2= 0.5046869922605142 \t Features Used= 10\n",
      "alpha= 1 : Test R2= 0.5059896195946609 \t Features Used= 9\n",
      "alpha= 10 : Test R2= 0.45065885109346004 \t Features Used= 4\n"
     ]
    }
   ],
   "source": [
    "#The above calculated lasso3 is calulated against default alpha value 1.0. Now let us vary the alpha value.\n",
    "\n",
    "#Computing lasso model for following alphas \n",
    "alphas = [0.0001,0.001,0.01,0.1,1,10]\n",
    "\n",
    "#Let us find test R2 and features used for each of the model\n",
    "test_R2 = []\n",
    "features_used = []\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a,max_iter=100000).fit(X2_train_scaled,y2_train)\n",
    "    test_R2.append(lasso.score(X2_test_scaled,y2_test))\n",
    "    features_used.append(np.sum(lasso.coef_ != 0))\n",
    "\n",
    "print('Obtained values are as follows:')\n",
    "for i in range(len(alphas)):\n",
    "    print(\"alpha=\",alphas[i],\": Test R2=\",test_R2[i],\"\\t Features Used=\",features_used[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b372c97",
   "metadata": {},
   "source": [
    "Plotting the test R2 vs the number of features used (i.e., those with non-zero coefficients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ba6314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23d4dbeca90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "symbols = ['^','*','s','o','p','v']\n",
    "for i,a in enumerate(alphas):\n",
    "    plt.plot(test_R2[i], features_used[i],symbols[i], label=\"Lasso alpha=\"+str(a))\n",
    "plt.xlim(0.45,0.51)\n",
    "plt.xlabel(\"Test R2\")\n",
    "plt.ylabel(\"Features used\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef581cc5",
   "metadata": {},
   "source": [
    "9.3) Which point on the curve do you prefer? </br>\n",
    "\n",
    "###### Alpha = 0.0001,0.001,0.01,0.1\n",
    "For such small values of alpha, we are using a model with all the 10 features. This means that our result is close to linear regression and we are not performing any model selection. This means we might be overfitting data so the model does not work very great on test set due to lack of generalization.\n",
    "\n",
    "###### Alpha = 1\n",
    "In this case, we are using 9 out of 10 features and achieved test R2 is also the highest. So looks like model selection is optimal where removing the one irrelavent feature reduces the model complexity and make it more generalized. This, in turn, helps to achieve good test R2.\n",
    "\n",
    "###### Alpha = 10\n",
    "Here, we are using a model with 4 out of 10 features which means there is a higher degree of model selection. But the achieved test R2 is relatively lower in this case. This is because the model complexity is lower and hence we might be undefitting the data. This underfitted model will lack generalization and will lead to poor performance on test set which is why we see lower test R2 in this case. \n",
    "\n",
    "Our regularization parameter, alpha, should be a tradeoff of: </br>\n",
    "<ol><li>Fitting the data well</li>\n",
    "    <li>Moving the parameter estimates to 0</li></ol>\n",
    "\n",
    "Hence, <strong>alpha = 1</strong> seems like the most optimal choice achieving highest test R2 at a slightly less complex model using 9 out of 10 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7783781",
   "metadata": {},
   "source": [
    "Parameter Selection using Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46ca73",
   "metadata": {},
   "source": [
    "Choosing the regularization parameter for the Lasso using cross-validation on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e11f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score: 0.47147475080220075\n",
      "Best regularization parameter alpha: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#Again using the below alphas as potential regularization parameters for Lasso\n",
    "alphas = [0.0001,0.001,0.01,0.1,1,10]\n",
    "best_score = 0\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a,max_iter=100000)\n",
    "    lasso.fit(X2_train_scaled,y2_train)\n",
    "    # perform cross-validation\n",
    "    scores = cross_val_score(lasso,X2_train_scaled, y2_train, cv=5)\n",
    "    # compute mean cross-validation accuracy\n",
    "    score = np.mean(scores)\n",
    "    # if we got a better score, store the score and parameters\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_alpha = a\n",
    "print(\"Best CV score:\", best_score)\n",
    "print(\"Best regularization parameter alpha:\", best_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1077b40c",
   "metadata": {},
   "source": [
    "Training the Lasso on the whole training set using the chosen values of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9274f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild a model on the full training set\n",
    "lasso = Lasso(alpha=best_alpha)\n",
    "lasso.fit(X2_train_scaled,y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a73b7b",
   "metadata": {},
   "source": [
    "Reporting the resulting training and test R2 and the number of features used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a84a1061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score with best parameters: 0.5103864679565968\n",
      "Test set score with best parameters: 0.5059896195946609\n",
      "Number of features used: 9\n"
     ]
    }
   ],
   "source": [
    "#Reporting the traning R2\n",
    "train_score = lasso.score(X2_train_scaled,y2_train)\n",
    "print(\"Training set score with best parameters:\", train_score)\n",
    "\n",
    "#Reporting the test R2\n",
    "test_score = lasso.score(X2_test_scaled,y2_test)\n",
    "print(\"Test set score with best parameters:\", test_score)\n",
    "\n",
    "#Reporting the number of features used\n",
    "features_used = np.sum(lasso.coef_ != 0)\n",
    "print('Number of features used:',features_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a36b804",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The above result in (10) coincides with our preference in (9).\n",
    "Alpha = 1 gives the best tradeoff between fitting the data well and performing the model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5341f39e",
   "metadata": {},
   "source": [
    "## Inductive Conformal Predictor Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb307f",
   "metadata": {},
   "source": [
    "Implementing an inductive conformal predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a186d0",
   "metadata": {},
   "source": [
    "a) Split the training set that you obtained in item 5 into two parts: the calibration set of size 99 and the rest of the training set (the training set proper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c71226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pr, X_calib, y_train_pr, y_calib = train_test_split(X2_train, y2_train, test_size=99, random_state=2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f332b8",
   "metadata": {},
   "source": [
    "b) Preprocess the training set proper, calibration set, and test set in the same way using StandardScaler. Namely, fit the scaler to the training set proper and then use it to transform all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24c39d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#fitting the scaler to the training set proper \n",
    "scaler.fit(X_train_pr)\n",
    "#transform training set proper\n",
    "X_train_pr_scaled = scaler.transform(X_train_pr)\n",
    "#transform calibration set\n",
    "X_calib_scaled = scaler.transform(X_calib)\n",
    "# transform test data\n",
    "X2_test_scaled = scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0d59c",
   "metadata": {},
   "source": [
    "c) Using the nonconformity measure α = |y − yhat|, where y is the true label and yhat is its prediction given the training set proper, for each test sample compute the prediction interval for it. Do this for significance levels 5% and 20%. For each of these significance levels compute:<ul>\n",
    "<li> the length of the prediction intervals for the test samples </li>\n",
    "<li> and the test error rate of your inductive conformal predictor. </li> </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23393d8e",
   "metadata": {},
   "source": [
    "###### Fit the Lasso with parameters chosen by cross-validation to the training set proper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed547a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score: 0.45595297318004324\n",
      "Best regularization parameter alpha: 1\n"
     ]
    }
   ],
   "source": [
    "#Computing the cross validation for below value of regularization parameter\n",
    "alphas = [0.0001,0.001,0.01,0.1,1,10,100]\n",
    "best_score = 0\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a,max_iter=100000)\n",
    "    lasso.fit(X_train_pr_scaled,y_train_pr)\n",
    "    # perform cross-validation\n",
    "    scores = cross_val_score(lasso,X_train_pr_scaled, y_train_pr, cv=5)\n",
    "    # compute mean cross-validation accuracy\n",
    "    score = np.mean(scores)\n",
    "    # if we got a better score, store the score and parameters\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_alpha = a\n",
    "print(\"Best CV score:\", best_score)\n",
    "print(\"Best regularization parameter alpha:\", best_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f67c232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild the model with best regularization parameter\n",
    "lasso = Lasso(alpha=best_alpha)\n",
    "lasso.fit(X_train_pr_scaled,y_train_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c3faa",
   "metadata": {},
   "source": [
    "######  Compute the $\\alpha$i for the calibration set by the formula $\\alpha$i = |yi − yhati| (yi being the true label and yhat being the Lasso prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1699d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the lasso predictions\n",
    "yhat = lasso.predict(X_calib_scaled)\n",
    "#Finding the non conformity scores\n",
    "alpha_scores = abs(y_calib - yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8eb2d1",
   "metadata": {},
   "source": [
    "###### Compute k and c\n",
    "Defining methods below to compute k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da36d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def getk(epsilon,m):\n",
    "    return math.ceil((1-epsilon)*(m+1))\n",
    "\n",
    "def getc(k, scores):\n",
    "    return scores[k-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ecbd1e",
   "metadata": {},
   "source": [
    "###### Finally, compute the prediction set for each test sample as [yhat−c, yhat+c], yhat being the Lasso prediction for this test sample\n",
    "Defining a method below that returns the prediction sets for all test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e1afcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredSets(c, X_test):\n",
    "    \"\"\"\n",
    "    Function to return prediction interval lengths\n",
    "    Input: c and test samples\n",
    "    Output: Prediction sets upper and lower limits for all test samples\n",
    "    \"\"\"\n",
    "    yhat = lasso.predict(X_test)\n",
    "    pred_set_min = yhat - c\n",
    "    pred_set_max = yhat + c\n",
    "    return pred_set_max, pred_set_min\n",
    "#Interpretation: For test sample i, the prediction set interval will be [pred_set_min[i],pred_set_max[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db6355d",
   "metadata": {},
   "source": [
    " #### Significance level 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7eeeaa",
   "metadata": {},
   "source": [
    "Computing k and c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c54cd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k for significance level 5%: 95\n",
      "Value of c for significance level 5%: 107.92978677890349\n"
     ]
    }
   ],
   "source": [
    "#size of calibration set\n",
    "m = X_calib_scaled.shape[0]\n",
    "#significance level 5%\n",
    "epsilon = 5/100\n",
    "#computing k\n",
    "k5 = getk(epsilon, m)\n",
    "#Sorting the alpha scores\n",
    "alpha_scores = np.sort(alpha_scores)\n",
    "#computing c\n",
    "c5 = getc(k5, alpha_scores)\n",
    "print('Value of k for significance level 5%:',k5)\n",
    "print('Value of c for significance level 5%:',c5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70af084",
   "metadata": {},
   "source": [
    "Computing the length of the prediction intervals for the test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c7f8427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of prediction intervals for all test samples at significance level 5%: 216.85957355780695\n"
     ]
    }
   ],
   "source": [
    "pred_set_max, pred_set_min = getPredSets(c5, X2_test_scaled)\n",
    "pred_interval_lengths = pred_set_max - pred_set_min + 1\n",
    "#The length of the prediction intervals for all the test samples will be same as it depends only on c:\n",
    "#The length of interval [yhat−c, yhat+c] will be (yhat+c) - (yhat−c) + 1 = 2c+1.\n",
    "#So we can take any value from the above pred_interval_lengths.\n",
    "print('Length of prediction intervals for all test samples at significance level 5%:',pred_interval_lengths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb02084",
   "metadata": {},
   "source": [
    "Computing the test error rate of inductive conformal predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdd1e3d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate at significance level 5%: 0.04504504504504504\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "test_set_size = len(y2_test)\n",
    "for i in range(test_set_size):\n",
    "    if pred_set_min[i] > y2_test[i] or y2_test[i] > pred_set_max[i]:\n",
    "        errors = errors + 1\n",
    "error_rate = errors/test_set_size\n",
    "print('Test error rate at significance level 5%:',error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e1987",
   "metadata": {},
   "source": [
    " #### Significance level 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3538b58",
   "metadata": {},
   "source": [
    "Computing k and c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d14df9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of k for significance level 5%: 80\n",
      "Value of c for significance level 5%: 77.67186206665784\n"
     ]
    }
   ],
   "source": [
    "#size of calibration set\n",
    "m = X_calib_scaled.shape[0]\n",
    "#significance level 5%\n",
    "epsilon = 20/100\n",
    "#computing k\n",
    "k20 = getk(epsilon, m)\n",
    "#Sorting the alpha scores\n",
    "alpha_scores = np.sort(alpha_scores)\n",
    "#computing c\n",
    "c20 = getc(k20, alpha_scores)\n",
    "print('Value of k for significance level 5%:',k20)\n",
    "print('Value of c for significance level 5%:',c20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2db7ce",
   "metadata": {},
   "source": [
    "Computing the length of the prediction intervals for the test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc2d4ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of prediction intervals for all test samples at significance level 20%: 156.34372413331567\n"
     ]
    }
   ],
   "source": [
    "pred_set_max, pred_set_min = getPredSets(c20, X2_test_scaled)\n",
    "pred_interval_lengths = pred_set_max - pred_set_min + 1\n",
    "#The length of the prediction intervals for all the test samples will be same as it depends only on c:\n",
    "#The length of interval [yhat−c, yhat+c] will be (yhat+c) - (yhat−c) + 1 = 2c+1.\n",
    "#So we can take any value from the above pred_interval_lengths.\n",
    "print('Length of prediction intervals for all test samples at significance level 20%:',pred_interval_lengths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3800d",
   "metadata": {},
   "source": [
    "Computing the test error rate of inductive conformal predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30b167bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate at significance level 20%: 0.12612612612612611\n"
     ]
    }
   ],
   "source": [
    "errors = 0\n",
    "test_set_size = len(y2_test)\n",
    "for i in range(test_set_size):\n",
    "    if pred_set_min[i] > y2_test[i] or y2_test[i] > pred_set_max[i]:\n",
    "        errors = errors + 1\n",
    "error_rate = errors/test_set_size\n",
    "print('Test error rate at significance level 20%:',error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d9419",
   "metadata": {},
   "source": [
    "#### <em>End of notebook</em>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
